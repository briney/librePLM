batch_size: 8
max_len: 1280
num_workers: 4
pin_memory: true


load_coords: null      # null=auto; false/true to force coordinates loading
prefetch_factor: 4     # per-worker prefetch depth (only used when num_workers > 0)


# file paths for datasets
# Training dataset(s). Supports both:
#   - Single dataset (100% sampling):
#       train: /path/to/train.parquet
#     (equivalently via CLI: `data.train=/path/to/train.parquet`)
#   - Multiple datasets with fractional sampling:
#       train:
#         dataset_a:
#           path: /path/to/dataset_a.parquet
#           fraction: 0.6
#         dataset_b:
#           path: /path/to/dataset_b.parquet
#           fraction: 0.4
#     (via CLI: `+data.train.dataset_a.path=... +data.train.dataset_a.fraction=...`)
#
# Notes:
#   - Fractions are normalized to sum to 1.0.
#   - You may omit some/all fractions; unspecified fractions share the remaining mass.
train: {}

# Eval dataset(s). Supports both:
#   - Single dataset:
#       eval: /path/to/eval.parquet
#     (via CLI: `data.eval=/path/to/eval.parquet`)
#   - Multiple datasets:
#       eval:
#         validation: /path/to/val.parquet
#         test: /path/to/test.parquet
#     (via CLI: `+data.eval.validation=... +data.eval.test=...`)
#   - Multiple datasets with per-dataset options:
#       eval:
#         validation:
#           path: /path/to/val.parquet
#           batch_size: 32
#           load_coords: true  # Per-dataset coordinate loading
#
# Per-dataset metric configuration:
#   Each eval dataset can specify which metrics to run:
#
#   - Whitelist approach (metrics.only): Run ONLY these metrics
#       eval:
#         seq_val:
#           path: /path/to/seq_val.parquet
#           load_coords: false
#           metrics:
#             only: [masked_accuracy, perplexity]  # Only run these metrics
#
#   - Enable/disable approach: Override individual metric settings
#       eval:
#         struct_val:
#           path: /path/to/struct_val.parquet
#           load_coords: true
#           metrics:
#             p_at_l:
#               enabled: true
#               contact_threshold: 6.0  # Override default threshold
#
#   - Hybrid approach: Combine 'only' with per-metric overrides
#       eval:
#         custom_val:
#           path: /path/to/custom.parquet
#           metrics:
#             only: [masked_accuracy, p_at_l]  # Start with this whitelist
#             p_at_l:
#               enabled: false  # But disable p_at_l (overrides 'only')
#             perplexity:
#               enabled: true   # And add perplexity (overrides 'only' exclusion)
#
# CLI examples:
#   # Single eval with metric whitelist:
#   procoder train data.train=... +data.eval.val.path=/path '+data.eval.val.metrics.only=[masked_accuracy,perplexity]'
#
#   # Multiple evals with different metrics:
#   procoder train data.train=... \
#     +data.eval.seq_val.path=/seq.parquet '+data.eval.seq_val.metrics.only=[masked_accuracy,perplexity]' \
#     +data.eval.struct_val.path=/struct.parquet +data.eval.struct_val.load_coords=true \
#     '+data.eval.struct_val.metrics.only=[masked_accuracy,p_at_l]'
eval: {}

# Iterable directory-of-parquet behavior tuning (ignored for single-file datasets)
shuffle_shards: true
shuffle_rows: true
